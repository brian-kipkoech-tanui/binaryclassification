{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1437b516",
   "metadata": {},
   "source": [
    "# Binary Classification: Expenditure Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d662439",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a6ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5dd87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       10000 non-null  int64  \n",
      " 1   gender    10000 non-null  int64  \n",
      " 2   marital   10000 non-null  float64\n",
      " 3   dep       10000 non-null  int64  \n",
      " 4   Income    10000 non-null  float64\n",
      " 5   Job yrs   10000 non-null  int64  \n",
      " 6   Town yrs  10000 non-null  int64  \n",
      " 7   Yrs Ed    10000 non-null  int64  \n",
      " 8   Dri Lic   10000 non-null  int64  \n",
      " 9   Own Home  10000 non-null  int64  \n",
      " 10  # Cred C  10000 non-null  int64  \n",
      " 11  Churn     10000 non-null  int64  \n",
      "dtypes: float64(2), int64(10)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel(\"./Expenditure-churn (3).xlsx\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4940c01",
   "metadata": {},
   "source": [
    "## Use a Pipeline to preprocess and fit binary classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c09b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features from target\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Standardise the whole dataset\n",
    "std_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "def preprocessor(X):\n",
    "    D = np.copy(X)\n",
    "    D = std_scaler.transform(D)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420bc99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(func=<function preprocessor at 0x0000023B7150CC18>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_transformer = FunctionTransformer(preprocessor)\n",
    "preprocess_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2906c8",
   "metadata": {},
   "source": [
    "### Fit a LogisticRegression() model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa16572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler',\n",
       "                 FunctionTransformer(func=<function preprocessor at 0x0000023B7150CC18>)),\n",
       "                ('Logistic Regression', LogisticRegression())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p1 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('Logistic Regression', LogisticRegression())])\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbc1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "def fit_and_print(p, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    # Fit the transformer\n",
    "    p.fit(X_train, y_train)\n",
    "    # Predict the train and test outputs\n",
    "    test_prediction =p.predict(X_test)\n",
    "    \n",
    "    # Print the errors\n",
    "    print(\"Accuracy Score:   \"+str(accuracy_score(test_prediction, y_test)*100))\n",
    "    print(\"Precision Score:  \"+str(precision_score(test_prediction, y_test)*100))\n",
    "    print(\"Recall Score:     \"+str(recall_score(test_prediction, y_test)*100))\n",
    "    print(\"roc_auc_score:    \"+str(accuracy_score(test_prediction, y_test)*100))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(test_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7461f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   99.44\n",
      "Precision Score:  98.32335329341318\n",
      "Recall Score:     100.0\n",
      "roc_auc_score:    99.44\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1665   14]\n",
      " [   0  821]]\n"
     ]
    }
   ],
   "source": [
    "fit_and_print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0a798",
   "metadata": {},
   "source": [
    "### Fit a RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "701caa5f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   98.56\n",
      "Precision Score:  97.96407185628743\n",
      "Recall Score:     97.7299880525687\n",
      "roc_auc_score:    98.56\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1646   17]\n",
      " [  19  818]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "p2 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('RFC', RandomForestClassifier())])\n",
    "fit_and_print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bae08d",
   "metadata": {},
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c5d434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 0.03753936938934116\n",
      "gender 0.0025993071716105738\n",
      "marital 0.0032149887099501323\n",
      "dep 0.004585368083725957\n",
      "Income 0.01788431192341633\n",
      "Job yrs 0.01868626002885181\n",
      "Town yrs 0.024382190821894634\n",
      "Yrs Ed 0.0237583870586684\n",
      "Dri Lic 0.0017683376331745356\n",
      "Own Home 0.007394257836903157\n",
      "# Cred C 0.8581872213424634\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier()\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "rnd_clf.fit(X, y)\n",
    "for name, score in zip(dataset.iloc[:,:-1].columns.to_list(), rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05df7c",
   "metadata": {},
   "source": [
    "### Fit a voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2078c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(kernel='linear', random_state=0)\n",
    "dec_clf = DecisionTreeClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('dec', dec_clf)],\n",
    "voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135724eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   99.4\n",
      "Precision Score:  98.20359281437125\n",
      "Recall Score:     100.0\n",
      "roc_auc_score:    99.4\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1665   15]\n",
      " [   0  820]]\n"
     ]
    }
   ],
   "source": [
    "p3 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('VCL', voting_clf)])\n",
    "fit_and_print(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69801f",
   "metadata": {},
   "source": [
    "### Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643cc153",
   "metadata": {},
   "source": [
    "both bagging and pasting allow training instances to be sampled several\n",
    "times across multiple predictors, but only bagging allows training instances to be sampled\n",
    "several times for the same predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1f38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "SVC(kernel='linear', random_state=0), n_estimators=500,\n",
    "max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d314714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   97.88\n",
      "Precision Score:  93.65269461077844\n",
      "Recall Score:     100.0\n",
      "roc_auc_score:    97.88\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1665   53]\n",
      " [   0  782]]\n"
     ]
    }
   ],
   "source": [
    "p4 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('VCL', bag_clf)])\n",
    "fit_and_print(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e6cac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Boosting with a Adaboost and DecisionTree and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99cbd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "algorithm=\"SAMME.R\", learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89dbe1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   99.52\n",
      "Precision Score:  99.28143712574851\n",
      "Recall Score:     99.28143712574851\n",
      "roc_auc_score:    99.52\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1659    6]\n",
      " [   6  829]]\n"
     ]
    }
   ],
   "source": [
    "p5 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('AdaCL', ada_clf)])\n",
    "fit_and_print(p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c5506",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63c06066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   99.2\n",
      "Precision Score:  98.80239520958084\n",
      "Recall Score:     98.80239520958084\n",
      "roc_auc_score:    99.2\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1655   10]\n",
      " [  10  825]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "p6 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('GBC', GradientBoostingClassifier())])\n",
    "fit_and_print(p6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9776d",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f0a4b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   99.52\n",
      "Precision Score:  99.52095808383234\n",
      "Recall Score:     99.04648390941597\n",
      "roc_auc_score:    99.52\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1657    4]\n",
      " [   8  831]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "p7 = Pipeline([('scaler', preprocess_transformer),\n",
    "              ('XGBC', XGBClassifier())])\n",
    "fit_and_print(p7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e93db",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ee477",
   "metadata": {},
   "source": [
    "* The Boosting algorithms (AdaBoost, GradientBoost, and XGBoost) performed better than all other models.\n",
    "* XGBoost was the best performing model overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beae2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# Fit the XGBoost model\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d223383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for y_test and y_pred\n",
    "data_dict = {\"Actual\": y_test, \"Prediction\": y_pred}\n",
    "results_df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "678cd037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Prediction\n",
       "0          1           1\n",
       "1          0           0\n",
       "2          0           0\n",
       "3          1           1\n",
       "4          0           0\n",
       "...      ...         ...\n",
       "2495       0           0\n",
       "2496       0           0\n",
       "2497       1           1\n",
       "2498       0           0\n",
       "2499       0           0\n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
